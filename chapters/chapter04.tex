\chapter{Descripción}\label{chapter04}

El presente capítulo desarrolla la descripción integral de la solución propuesta, abordando sus fundamentos conceptuales, técnicos y operativos. Se expone la forma en que la plataforma materializa los objetivos definidos en las etapas de análisis, describiendo los principales componentes que la conforman y la lógica que guía su funcionamiento. Asimismo, se presenta la manera en que las decisiones de diseño, arquitectura y desarrollo se articulan para garantizar la eficiencia, la escalabilidad y la confiabilidad del sistema.

\section{Requerimientos}\label{sec:requerimientos}
A continuación se presentan los requerimientos de la solución, organizados en dos categorías: requerimientos funcionales y no funcionales. Los requerimientos funcionales representan las operaciones y servicios que la plataforma debe ofrecer al usuario final, mientras que los no funcionales establecen criterios de calidad que condicionan la forma en que el sistema debe operar \parencite{ieee2008}.

SmartStocker está diseñado para asistir a pequeños y medianos establecimientos gastronómicos en la gestión de su inventario. A partir de la integración con plataformas de ventas y el análisis de datos históricos mediante técnicas de Machine Learning, el sistema proyecta la demanda futura, calcula el stock necesario y genera alertas tempranas para evitar pérdidas por desabastecimiento o exceso. Asimismo, provee un tablero con métricas relevantes y permite al usuario interactuar con el modelo de predicción para ajustarlo a la realidad de su negocio mediante feedback.

\subsection{Requerimientos funcionales}\label{sec:requerimientos-funcionales}
Los requerimientos funcionales describen las acciones observables que el sistema debe llevar a cabo para satisfacer las necesidades del usuario \parencite{ieee2008}.
\begin{enumerate}[label=\textbf{RF\arabic*}, leftmargin=2.5cm]
    \item El sistema debe permitir el alta de cuentas de restaurantes, con autenticación segura mediante correo electrónico y contraseña.
    \item El sistema debe permitir registrar, modificar y eliminar productos gastronómicos, vinculados con los insumos que los componen.
    \item El sistema debe facilitar la administración de inventario, incluyendo actualización de cantidades disponibles y definición de umbrales mínimos de stock.
    \item El sistema debe conectarse con plataformas de delivery en CABA (por ejemplo, PedidosYa) para importar datos de ventas en tiempo real.
    \item El sistema debe permitir la carga manual de datos históricos de ventas a través de archivos en formato \texttt{.csv} o \texttt{.xlsx}.
    \item El sistema debe ejecutar predicciones de ventas que sean basadas en modelos de Machine Learning, considerando tanto información histórica como variables externas (clima, feriados, días de la semana).
    \item El sistema debe calcular automáticamente la cantidad de inventario recomendada según los resultados de las predicciones generadas.
    \item El sistema debe emitir alertas cuando un insumo se encuentre por debajo del nivel mínimo configurado por el usuario.
    \item El sistema debe permitir al usuario proporcionar retroalimentación respecto a las predicciones, incorporando estos datos para el ajuste del modelo.
\end{enumerate}

\subsection{Requerimientos no funcionales}\label{sec:requerimientos-no-funcionales}
Los requerimientos no funcionales especifican condiciones de calidad y restricciones técnicas que determinan cómo debe operar la solución, más allá de las funciones explícitas que ofrece \parencite{ieee2008}.
\begin{enumerate}[label=\textbf{RNF\arabic*}, leftmargin=2.8cm]
    \item La interfaz debe ser adaptable (responsive) para asegurar su correcto uso en computadoras de escritorio, tablets y dispositivos móviles.
    \item La aplicación debe garantizar disponibilidad continua, las veinticuatro horas del día, los siete días de la semana, para el acceso a predicciones, métricas e informes en cualquier momento.
    \item El sistema debe ser compatible con los navegadores más utilizados (Google Chrome, Mozilla Firefox, Microsoft Edge y Safari) en sus versiones estables recientes.
    \item La infraestructura debe poder escalar automáticamente para soportar un crecimiento sostenido de usuarios sin afectar el rendimiento.
    \item El sistema debe desplegarse en una plataforma en la nube (por ejemplo, AWS Amplify) que garantice al menos un 99\% de disponibilidad mensual.
\end{enumerate}

\section{Diagramas}\label{sec:diagramas}

Para comprender de manera clara la interacción entre los usuarios y el sistema, así como el flujo de los procesos internos, se emplean diferentes tipos de diagramas. Estas representaciones gráficas permiten comunicar de forma visual los requerimientos, las funcionalidades y la lógica de operación de la aplicación, favoreciendo la comprensión tanto de aspectos funcionales como de diseño \parencite{booch2005uml}. 

A continuación, se detallan los posibles flujos funcionales que se encuentran disponibles en SmartStocker.

\subsection{Diagramas de Casos de Uso}\label{sec:diagramas-casos-uso}

Un diagrama de caso de uso es una representación visual que muestra cómo los actores (usuarios u otros sistemas) interactúan con las funcionalidades principales de una aplicación. Estos diagramas permiten modelar el comportamiento esperado desde el punto de vista del usuario, identificando qué operaciones puede ejecutar y cómo se relacionan con el sistema \parencite{jacobson1992usecase}.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{images/DiagramaCasosDeUsoTesis.png}
    \caption{Diagrama de Casos de Uso}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:casos-de-uso}
\end{figure}

\subsection{Diagramas de Flujo}\label{sec:diagramas-flujo}

Los diagramas de flujo o de procesos son herramientas visuales que representan de manera secuencial los pasos y decisiones que conforman un procedimiento. Su utilización permite clarificar la lógica del negocio, identificar posibles ineficiencias y redundancias, así como facilitar la comunicación entre los equipos técnicos y los usuarios. De esta manera, constituyen un recurso fundamental para comprender, analizar, documentar y mejorar procesos organizacionales \parencite{asq2025flowchart}.

\subsubsection{Registro y Autenticación}
Con el fin de garantizar la seguridad y la personalización de los datos, el acceso a la información y a las funcionalidades críticas de SmartStocker se encuentra restringido a usuarios autenticados. Para ello, la plataforma implementa un flujo de registro inicial y un mecanismo de inicio de sesión que permite identificar de manera única a cada restaurante o local gastronómico.

Durante la etapa de registro, el usuario completa un formulario en línea con los datos básicos del negocio.Estos datos son validados por el sistema para comprobar su integridad y formato. En caso de inconsistencias, el sistema informa los errores y solicita su corrección antes de continuar. Si la información ingresada es válida, SmartStocker redirige al usuario a la página de inicio y registra la solicitud correspondiente. Posteriormente, la empresa valida y aprueba el alta del negocio, enviando un correo electrónico con las credenciales definitivas de acceso y confirmando la activación de la cuenta en el entorno B2B. Este proceso garantiza que cada registro corresponda efectivamente a un establecimiento gastronómico verificado, asegurando así la integridad de la red y la trazabilidad de los datos administrados por la plataforma.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{images/DiagramaRegistroDeUsuarioB2B.png}
    \caption{Flujo de Registro del Usuario.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:flujo-registro}
\end{figure}

Posteriormente, mediante la autenticación, los usuarios acceden a su espacio de trabajo personalizado, desde el cual es posible consultar métricas, visualizar predicciones de demanda, administrar productos e ingredientes y recibir alertas relacionadas con el stock disponible. Este proceso de inicio de sesión no solo protege la integridad de la información, sino que también garantiza que las recomendaciones generadas por el sistema respondan a las características particulares de cada negocio gastronómico.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{images/DiagramaInicioDeSesion.png}
    \caption{Flujo de Autenticación del Usuario.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:flujo-autenticacion}
\end{figure}

\subsubsection{Generación de Predicciones}

La capacidad de anticipar la demanda de productos constituye la funcionalidad central de SmartStocker, ya que permite a los restaurantes y locales gastronómicos tomar decisiones fundamentadas sobre compras y reposiciones de insumos. En este proceso, el sistema aplica modelos de Machine Learning que, a partir de datos históricos y variables externas, generan estimaciones confiables de ventas futuras.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{images/DiagramaDePrediccionTesis.png}
    \caption{Flujo de Predicción de Ventas.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:flujo-prediccion}
\end{figure}

\section{Identidad de marca}\label{subsec:identidad-marca}
SmartStocker es una marca centrada en la toma de decisiones basada en datos para la gestión de inventarios gastronómicos. Su identidad se sostiene en tres ejes: claridad (información entendible y accionable), confiabilidad (resultados consistentes) y agilidad (respuestas oportunas para planificar compras y evitar quiebres o excedentes). La narrativa de marca comunica simplicidad y precisión: transformar registros de venta y contexto operativo en recomendaciones concretas de stock y alertas preventivas.

\subsection{Misión}\label{subsec:mision}
Impulsar la rentabilidad de restaurantes y locales gastronómicos mediante una plataforma que integra datos de venta en tiempo real, predice la demanda y traduce esos resultados en recomendaciones de compra y niveles de stock accionables. SmartStocker reduce quiebres y desperdicios, simplifica la operación diaria y convierte la gestión de inventario en un proceso preciso, automatizado y basado en evidencia.

\subsection{Visión}\label{subsec:vision}
Ser la referencia regional en optimización de inventarios gastronómicos mediante analítica predictiva, integrando datos operativos y conocimiento experto para elevar la toma de decisiones cotidiana.

\subsection{Nombre}\label{subsec:nombre}
El nombre SmartStocker combina \textit{Smart} (inteligente) y \textit{Stocker} (almacenista). La construcción comunica de manera directa el beneficio central: administrar inventarios con inteligencia. Es breve, fácil de pronunciar y recordar, y al estar en inglés facilita su adopción en distintos mercados y contextos tecnológicos.

\subsection{Identidad visual}\label{subsec:identidad-visual}
\paragraph{Concepto.} La identidad visual representa el pasaje de datos a decisiones. Se recurre a formas claras y proporciones estables que remiten a control, previsión y orden, evitando recursos recargados que resten legibilidad en entornos digitales.

\paragraph{Logotipo tipográfico.}
El logotipo tipográfico prioriza legibilidad y memorabilidad. La diferenciación visual se logra por color: \textit{Smart} en tono oscuro (negro/gris muy profundo) y \textit{Stocker} en azul corporativo, lo que facilita la lectura y refuerza el territorio semántico del producto (gestión de stock). Además, se utiliza capitalización inicial en cada palabra y composición en una sola línea.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.80\textwidth]{images/smartstocker-logotipo-tipografico.png}
    \caption{Logotipo tipográfico de SmartStocker.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:logo-tipografico-smartstocker}
\end{figure}

\paragraph{Imagotipo (isotipo + logotipo).}
El imagotipo integra un isotipo geométrico que sugiere \textit{contenedor/caja} (inventario) y una flecha ascendente (proyección/abastecimiento), combinado con el logotipo. El isotipo admite uso independiente en tamaños reducidos (favicon, icono de app), mientras que el imagotipo es la versión preferente para cabeceras, presentaciones y piezas institucionales.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.70\textwidth]{images/smartstocker-imagotipo.png}
    \caption{Imagotipo de SmartStocker (composición isotipo + logotipo).}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:imagotipo-smartstocker}
\end{figure}

\subsection{Paleta de Colores}\label{subsec:paleta-colores}

El diseño visual de SmartStocker se sustenta en una paleta cromática la cual fue escogida con el propósito de transmitir profesionalismo, confianza y modernidad, atributos que resultan esenciales en un sistema orientado a la toma de decisiones estratégicas en el sector gastronómico. Ahora bien, la elección de los tonos se realizó considerando tanto la dimensión estética como la funcionalidad comunicativa de cada color dentro de la interfaz.

Los colores principales corresponden a una gama de azules, donde el azul corporativo (\#1E40AF) se utiliza en encabezados, botones primarios y elementos de navegación clave. Este tono se asocia tradicionalmente con la seriedad, la estabilidad y la confianza, lo que refuerza la credibilidad del sistema frente a los usuarios que deben basar sus decisiones en datos precisos. Como complemento, el azul claro (\#3B82F6) aparece en estados de interacción como hover y en componentes secundarios, aportando un contraste visual que mantiene la coherencia cromática y facilita la detección rápida de acciones disponibles.

En cuanto a los colores semánticos, se definieron tres que cumplen un rol fundamental en la comunicación de estados del sistema: verde éxito (\#10B981), naranja advertencia (\#F59E0B) y rojo crítico (\#EF4444). Estos colores no solo cumplen con la convención culturalmente reconocida (verde como positivo, rojo como error), sino que también permiten que el usuario identifique de forma inmediata la condición de un insumo o la validez de una acción.

Los colores de apoyo, grises en diferentes intensidades y blanco como fondo principal, cumplen la función de dar equilibrio visual. El gris oscuro (\#1F2937) se emplea en textos principales para asegurar legibilidad, mientras que el gris medio (\#6B7280) se reserva para información secundaria, evitando así la sobrecarga cognitiva. Además, el gris claro (\#F3F4F6) y el azul muy claro (\#EFF6FF) sirven como fondos sutiles y separadores, permitiendo estructurar la información en bloques diferenciados sin necesidad de líneas divisorias excesivas.

En conjunto, esta paleta de colores no responde únicamente a una intención estética, sino que está al servicio de la usabilidad, la accesibilidad y la experiencia de usuario. Cada tonalidad se integra en un sistema visual coherente que facilita la navegación, refuerza el reconocimiento de patrones y garantiza que los usuarios puedan interactuar con la plataforma de forma intuitiva y eficiente.

\begin{table}[htbp]
\centering
\caption{Paleta de colores empleada en SmartStocker.}
\label{tab:paleta-colores}

\renewcommand{\arraystretch}{1.25}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Categoría} & \textbf{Color} & \textbf{Código Hex} \\ \hline
Azul corporativo & \cellcolor[HTML]{1E40AF} & \#1E40AF \\ \hline
Azul claro & \cellcolor[HTML]{3B82F6} & \#3B82F6 \\ \hline
Verde éxito & \cellcolor[HTML]{10B981} & \#10B981 \\ \hline
Naranja advertencia & \cellcolor[HTML]{F59E0B} & \#F59E0B \\ \hline
Rojo crítico & \cellcolor[HTML]{EF4444} & \#EF4444 \\ \hline
Gris oscuro (texto principal) & \cellcolor[HTML]{1F2937} & \#1F2937 \\ \hline
Gris medio (texto secundario) & \cellcolor[HTML]{6B7280} & \#6B7280 \\ \hline
Gris claro (fondos) & \cellcolor[HTML]{F3F4F6} & \#F3F4F6 \\ \hline
Azul muy claro (fondos) & \cellcolor[HTML]{EFF6FF} & \#EFF6FF \\ \hline
\end{tabular}

\vspace{0.3em}
\captionsetup{justification=centering}
{\small \textit{Fuente: Elaboración propia.}}
\end{table}

\subsection{Pantallas de la aplicación}\label{subsec:pantallas-aplicacion}
A continuación se presentan las principales pantallas de la aplicación SmartStocker, ordenadas según el flujo de interacción. Estas capturas abarcan: la experiencia inicial (Figuras~\ref{fig:ux-landing1} a \ref{fig:ux-landing5} y \ref{fig:ux-login}); el dashboard (Figuras~\ref{fig:ux-dashboard1} a \ref{fig:ux-dashboard3}); la gestión de datos (Figuras~\ref{fig:ux-ingredientes}, \ref{fig:ux-items}, \ref{fig:ux-nuevo-item} y \ref{fig:ux-nuevo-ingrediente}); y las funcionalidades de predicción de ventas (Figuras~\ref{fig:ux-predicciones} a \ref{fig:ux-prediccion2}).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/landing1.png}
    \caption{Pantalla de inicio (Landing) – Parte 1.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-landing1}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/landing2.png}
    \caption{Pantalla de inicio (Landing) – Parte 2.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-landing2}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/landing3.png}
    \caption{Pantalla de inicio (Landing) – Parte 3.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-landing3}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/landing4.png}
    \caption{Pantalla de inicio (Landing) – Parte 4.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-landing4}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/landing5.png}
    \caption{Pantalla de inicio (Landing) – Parte 5.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-landing5}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/login.png}
    \caption{Pantalla de inicio de sesión.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-login}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/dashboard1.png}
    \caption{Dashboard – Vista general con métricas clave.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-dashboard1}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/dashboard2.png}
    \caption{Dashboard – Predicciones de demanda y niveles de stock sugeridos.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-dashboard2}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/dashboard3.png}
    \caption{Dashboard – Alertas y seguimiento de inventario por insumo.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-dashboard3}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/ingredientes.png}
    \caption{Pantalla de gestión de ingredientes.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-ingredientes}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/items.png}
    \caption{Pantalla de gestión de ítems.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-items}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/nuevoItem.png}
    \caption{Pantalla para agregar un nuevo ítem.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-nuevo-item}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/nuevoIngrediente.png}
    \caption{Pantalla para agregar un nuevo ingrediente.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-nuevo-ingrediente}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/predicciones.png}
    \caption{Pantalla consolidada de predicciones.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-predicciones}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/prediccion1.png}
    \caption{Resultado de predicciones.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-prediccion1}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/prediccion2.png}
    \caption{Ingredientes necesarios.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:ux-prediccion2}
\end{figure}

\section{Funcionalidades}\label{sec:funcionalidades}

\subsection{Predicción de Ventas}\label{sec:prediccion-ventas}

En el sector gastronómico, la capacidad de anticipar la demanda se ha convertido en un factor estratégico para reducir pérdidas, optimizar el uso de insumos y garantizar la continuidad del servicio. Bajo dicha premisa, SmartStocker incorpora un módulo de predicciones como una de sus funcionalidades principales. El sistema aplica técnicas de aprendizaje automático que permiten transformar datos históricos y registros actuales en estimaciones de ventas futuras. 

El objetivo de esta funcionalidad es reemplazar las decisiones basadas únicamente en la experiencia o la intuición por un enfoque sistemático apoyado en datos, incrementando la objetividad en la gestión del inventario. Además, su integración con fuentes externas de información le otorga la capacidad de adaptarse a contextos cambiantes, como la estacionalidad, los feriados o incluso factores climáticos que pueden influir en el consumo.

\subsection{Fuentes de Datos}\label{sec:fuentes-datos}

El modelo predictivo requiere datos de calidad para generar resultados confiables. Con este fin, la plataforma web admite dos vías principales de recopilación:

\begin{itemize}
    \item \textbf{Carga manual de datos mediante archivos CSV}: esta modalidad permite a los locales gastronómicos incorporar sus registros históricos directamente desde sistemas internos o planillas de control. Para este fin, se determinó que el formato esperado para archivos CSV es:
    \begin{itemize}
        \item Fecha venta: dd/mm/aaaa hh:mm:ss
        \item Producto: con el mismo nombre usado al generar el producto en la aplicación.
        \item Cantidad.
    \end{itemize}

    \item \textbf{Integración automática con sistemas de venta}: este mecanismo posibilita la importación continua de pedidos en tiempo real desde aplicaciones como PedidosYa. Con ello, el sistema asegura la actualización permanente del conjunto de datos, reduciendo la dependencia exclusiva de registros históricos y adaptándose a la dinámica diaria del negocio.
\end{itemize}

\subsection{Gestion de ingredientes e items del menu}\label{sec:carga-datos}

Para que el sistema pueda calcular el inventario sugerido, es necesario que el usuario cargue los ingredientes que utiliza en su local y los vincule con los productos gastronómicos que ofrece en su menú. Esta funcionalidad permite al usuario definir y administrar tanto los ingredientes como los items del menu, permitiendo, en el caso particular de los ingredientes, realizar esta carga no solo desde la UI, sino tambien de forma masiva a traves de un archivo, a fin de simplificar la operatoria en caso de que el usuario cuente con un listado extenso.

\subsection{Procesamiento Predictivo}\label{sec:procesamiento-predictivo}

El procesamiento predictivo constituye el núcleo técnico de la funcionalidad de SmartStocker. Una vez recopilados los datos históricos y actuales, el sistema los somete a un proceso de depuración y normalización que asegura la consistencia y homogeneidad de los registros. Este preprocesamiento incluye la eliminación de valores atípicos, la imputación de datos faltantes y la transformación de variables temporales (como la estacionalidad o los turnos horarios) en características relevantes para el modelo.

Posteriormente, los datos son utilizados para entrenar algoritmos de aprendizaje supervisado, dentro de los cuales se evaluaron diferentes enfoques, priorizando modelos de regresión y técnicas de boosting como CatBoost, debido a su robustez en contextos con variables categóricas y a su capacidad de reducir el overfitting. Estos modelos generan proyecciones de ventas futuras en base a patrones identificados, incorporando tanto las tendencias históricas como variables externas tales como clima, feriados y días de la semana.

Las predicciones se ejecutan bajo demanda, es decir, cada vez que el usuario lo requiera dentro de la plataforma, lo que garantiza resultados actualizados y adaptados al contexto puntual de planificación del negocio, integrando un mecanismo de retroalimentación continua (feedback loop) mediante el cual los usuarios validan si las estimaciones reflejaron la demanda real observada; esa información se reintegra al modelo para ajustar progresivamente su precisión, personalizando las predicciones al contexto específico de cada restaurante y favoreciendo la evolución de SmartStocker ante escenarios cambiantes.

En consecuencia, el procesamiento predictivo de SmartStocker no se limita a entregar un valor numérico de ventas estimadas, sino que constituye un sistema adaptable y evolutivo, orientado a respaldar la toma de decisiones estratégicas en la gestión de inventarios gastronómicos.

\subsection{Cálculo de Inventario Sugerido}\label{sec:calculo-inventario}

Una vez obtenidas las predicciones de ventas, los resultados obtenidos son vinculados con la lista de ingredientes definida por el restaurante. De esta manera, se genera un cálculo automático del inventario recomendado, minimizando tanto los riesgos de desabastecimiento como los costos derivados de un exceso de stock. 

\subsection{Notificación de Alertas}\label{sec:alertas}

El módulo de notificaciones cumple un rol preventivo. Cada vez que un insumo alcanza un nivel inferior al umbral configurado por el usuario, el sistema genera una alerta en el tablero principal y, en futuras versiones, podrá enviarlas vía correo electrónico o notificaciones push.

El valor de este componente radica en su capacidad para evitar interrupciones operativas. En un negocio gastronómico, la ausencia de un ingrediente clave no solo afecta la venta de un plato específico, sino que también impacta en la experiencia del cliente y en la reputación del local. Por esta razón, las alertas de stock bajo no deben considerarse únicamente como un aviso técnico, sino como un mecanismo de aseguramiento de la calidad del servicio.

\section{Tecnologías utilizadas}\label{sec:tecnologias-utilizadas}

SmartStocker se basa en una serie de tecnologías y herramientas que permiten su funcionamiento eficiente y escalable. A continuación, se detallan las principales tecnologías utilizadas en el desarrollo de la solución:

\subsection{Next.js}\label{sec:nextjs}

Framework basado en React que permite crear aplicaciones web optimizadas con renderizado del lado del servidor. El uso de React se basa en que es ampliamente utilizado en el ecosistema de desarrollo frontend actual, lo que simplifica su mantenimiento a futuro y nos provee de múltiples librerías para utilizar en el desarrollo.

\subsection{Express}\label{sec:express}

Framework de Node.js que facilita la creación de aplicaciones web y APIs. Utilizado debido a que es fácilmente desplegable de forma serverless, y porque no se detectó la necesidad de utilizar un lenguaje fuertemente tipado.

\subsection{Python}\label{sec:python}

Lenguaje de programación de alto nivel, versátil y ampliamente utilizado en ciencia de datos y machine learning. Su uso radica en la enorme cantidad de librerías disponibles para realizar trabajos con datasets, tales como Panda y Numpy, entre otras.

\subsection{Amazon Web Services}\label{sec:aws}

Para el despliegue y operación de SmartStocker se utiliza Amazon Web Services (AWS), una plataforma en la nube que permite implementar una arquitectura escalable, segura y altamente disponible. Dentro del ecosistema de AWS se emplean los siguientes servicios principales

\begin{itemize}
    \item \textbf{AWS Amplify:} Plataforma que simplifica la creación, configuración y despliegue de aplicaciones web y móviles, integrando backend, hosting y flujos de desarrollo continuo. Se optó por su uso a fin de simplificar lo más posible los aspectos relacionados al despliegue del frontend, su capacidad de escalamiento ante la demanda, y su soporte nativo para Next.js.

    \item \textbf{Amazon S3 (Simple Storage Service):} Servicio de almacenamiento de objetos que permite guardar y recuperar grandes volúmenes de datos de forma segura, duradera y altamente disponible. Se optó por su uso debido a que, por su bajo costo y durabilidad, nos permite guardar de forma segura los datos históricos y modelos entrenados para cada usuario.

    \item \textbf{AWS Lambda:} Servicio de computación serverless que permite ejecutar código en respuesta a eventos sin necesidad de administrar servidores. Se decidió su uso a fin de facilitar la gestión de los procesos que corren en los pipelines y para reducir costos, dado que AWS factura su uso únicamente en base a las ejecuciones realizadas.

    \item \textbf{Amazon EventBridge:} Servicio de gestión de eventos que facilita la conexión entre aplicaciones y la automatización de flujos mediante reglas y programación de tareas. Cumple de forma nativa con nuestro requerimiento de realizar entrenamientos de forma periódica.

    \item \textbf{Amazon SageMaker:} Plataforma integral de machine learning que permite construir, entrenar y desplegar modelos de Machine Learning. Como la solución nativa de AWS para este tipo de aplicaciones, nos provee la capacidad de ejecutar nuestros procesos dentro de su entorno, lo que permite contar con una mayor disponibilidad de recursos en comparación con otras alternativas, como EC2 o Lambda.

    \item \textbf{Amazon DocumentDB:} Servicio de base de datos NoSQL compatible con MongoDB, diseñado para almacenar, consultar y escalar datos en formato de documentos JSON. Ofrece alta disponibilidad, seguridad integrada y capacidad de escalado automático. Se decidió optar por su uso tanto por la flexibilidad que otorga en términos de esquema como por su integración natural con Node.js.

    \item \textbf{Amazon SQS (Simple Queue Service):} Servicio de colas de mensajería que permite desacoplar y coordinar componentes de sistemas distribuidos. Facilita la comunicación asíncrona, el procesamiento escalable y la tolerancia a fallos entre servicios. Se incluyó en la solución a fin de ejecutar ciertos procesos de forma asíncrona, separados del componente que los inició originalmente, como el procesamiento de una venta.
\end{itemize}

\section{Arquitectura de la solución}\label{sec:arquitectura-solucion}
En esta sección se presenta la arquitectura de SmartStocker, detallando como las tecnologías empleadas se implementan en el diseño técnico y funcional. La arquitectura funciona como marco conceptual que sustenta cada componente del sistema y especifica las interacciones y dependencias entre las distintas partes que lo componen.

\subsection{Diagrama de Arquitectura conceptual}\label{sec:arquitectura-conceptual}
En relación con la arquitectura de alto nivel de SmartStocker, se propone un modelo de tres capas que organiza la solución, asegurando una separación clara de responsabilidades y mejorando la escalabilidad. Esta estructura está diseñada para optimizar tanto la interacción con el usuario como el procesamiento y almacenamiento de los registros de venta y los resultados de inferencia generados por el modelo predictivo.

La primera capa —Capa de Presentación (Presentation Layer)— agrupa la interfaz y la experiencia de usuario. En ella se implementa el frontend de SmartStocker con Next.js y se despliega mediante AWS Amplify, aprovechando sus capacidades de hosting y CI/CD. Esta capa permite a los usuarios interactuar con la plataforma, gestionar sus productos e ingredientes, visualizar recomendaciones y alertas, y realizar operaciones de predicciones de venta de forma responsiva y orientada a la operativa diaria.

La Capa de Negocio (Business Layer) constituye el núcleo lógico de SmartStocker y se organiza en tres componentes principales. El primero es una API REST que actúa como puente entre la capa de presentación y los servicios backend; a través de ella se gestionan las sesiones y la autorización, se exponen los endpoints para solicitar predicciones y gestionar productos, ingredientes, y alertas, y se incluye la lógica necesaria para atender las demandas de la interfaz de usuario de forma segura y consistente. Esta se encuentra desarollada con Node.js, a fin de aprovechar lo mas posible su integracion nativa con Next.js, y la simpleza a la hora de desplegar la API de forma serverless mediante AWS Lambda. El segundo es el pipeline de ETL, encargado de recibir los datos de ventas en tiempo real desde los sistemas externos, procesarlos, enriquecerlos, y dejarlos listos para ser usados por el modelo. Por último, el pipeline de ML será el encargado de realizar el entrenamiento del modelo, ya sea de forma periódica u bajo demanda, y de dejarlo disponible para su uso en las operaciones de inferencia. La logica de ambos pipelines se encuentra desarollada en Python, a fin de aprovechar las distintas librerías y frameworks disponibles para el procesamiento de datos y machine learning, y se encuentran implementados mediante AWS Lambda.

Por último, la Capa de Almacenamiento (Storage Layer) se organiza según los distintos casos de uso de la plataforma y está diseñada para optimizar rendimiento y costos. Los datos de la aplicación, tales como los ingredientes, productos, ventas realizadas,  y resultados de predicciones, se almacenan en DocumentDB, lo que facilita lecturas de baja latencia y flexibilidad en la estructura de los datos. Mientras tanto, los datos orientados al entrenamiento del modelo, tales como los datasets históricos, los artefactos de entrenamiento y los modelos exportados se almacenan en Amazon S3, aprovechando su durabilidad y su bajo costo.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/arquitectura_capas.png}
    \caption{Arquitectura conceptual de SmartStocker.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:arquitectura-conceptual}
\end{figure}

\subsection{Diagrama de Despliegue}\label{sec:arquitectura-despliegue}
Se decidió usar Amazon Web Services (AWS) como solución de despliegue debido a la flexibilidad y amplitud de herramientas ofrecidas necesarias para implementar la arquitectura de SmartStocker.

Analizando la capa de presentación, esta se encuentra desarrollada con Next.js, y desplegado a través de AWS Amplify. Se eligió este servicio puesto que simplifica enormemente la gestión de la aplicación, permitiendo, mediante una simple configuración inicial, encargarse de aspectos tales como el despliegue (permitiendo CI/CD integrado a GitHub), hasta del escalamiento en sí.

Para la capa de almacenamiento, se optaron por dos soluciones. Primero, DocumentDB como base de datos NoSQL, seleccionado debido a la naturaleza no estructurada de los datos a utilizar, y que nos brinda la posibilidad de modificar el schema con facilidad, además de ser una base serverless escalable. Y segundo, S3, para contener la información en formato \verb|csv| requerida para los entrenamientos del modelo, y para almacenar los archivos correspondientes al modelo entrenado en si.

Para la capa de negocio, se decidió implementar las distintas APIs requeridas mediante AWS Lambda, dado que su enfoque serverless permite abstraernos de la gestión de la infraestructura, acelerando el desarrollo y la puesta en producción, escalando cuando la demanda lo requiera, y reduciendo los costos fijos.

Esto también aplica para el pipeline de ETL, donde también se utiliza AWS Simple Queue Service (SQS) para desacoplar el procesamiento de las ventas, a fin de lograr velocidades de respuesta rápida ante los sistemas externos que enviaran las mismas, mientras que el procesamiento y enriquecimiento de las ventas se realiza en otra Lambda.

Por último, se decidió usar AWS Sagemaker en el pipeline de ML, puesto que simplifica el entrenamiento del modelo, requiriendo suministrarle los dataset de entrenamiento y validación a utilizar, y permite disponibilizar el modelo para ser usado para predicciones mediante endpoints, lo que brinda una consulta rápida y de facil implementacion.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/arquitectura_despliegue.png}
    \caption{Arquitectura de Despliegue y Procesos de SmartStocker.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:arquitectura-despliegue}
\end{figure}

\subsection{Diagrama de Base de datos}\label{sec:arquitectura-base-datos}

Para el diseño de la base de datos, se opto por utilizar DocumentDB, una de las alternativas NoSQL brindadas por AWS, debido a la flexibilidad y capacidades de escalado automatico que esta nos provee, siendo la flexibilidad del schema algo critico dada la necesidad de agregar campos adicionales conforme el proceso de ETL o entrenamiento del modelo de ML lo requieran.

El diseño de la base de datos se estructura en torno a siete entidades principales: Usuario, ItemMenu, Ingrediente, ItemMenu\_Ingrediente, Venta, DetalleVenta,CorreccionPrediccion y Alerta.
La entidad Usuario representa a cada negocio dentro de la plataforma, almacenando información básica de acceso (nombre de usuario, email, contraseña), su estado de actividad y los identificadores de integración con plataformas externas como PedidosYa, Rappi u OláClick.

La entidad Ingrediente contiene los insumos del negocio, registrando su nombre, unidad de medida, cantidad en stock, cantidad mínima y unidad de stock, además del userId propietario, mientras que ItemMenu registra los productos ofrecidos (código, nombre, estado activo) y contiene la lista de ingredientes necesarios para cada receta. Esa relación $N..M$ entre ItemMenu e Ingrediente se materializa en la tabla/intersección (el subdocumento de ingredientes) que guarda, por cada par producto-ingrediente, la cantidad\_requerida. 

La entidad Predicción registra las predicciones de demanda vinculadas a un producto\_id (ItemMenu) con fecha\_prediccion, turno, cantidad\_predicha y el userId que la generó.

La entidad Venta registra las transacciones realizadas, incluyendo el número de venta, fecha, turno, método de pago, plataforma de venta, estado y cantidad total de ítems, todo asociado a un userId y a su vez una se descompone en varios ítems dentro de la entidad DetalleVenta, donde se detallan el producto (ItemMenu), la cantidad, el precio unitario y el subtotal, lo que permite realizar análisis más precisos por producto y turno.

La entidad CorreccionPrediccion guarda el feedback explícito del usuario sobre los valores predichos por el modelo. Cada registro asocia un itemMenuId y un userId con la predicción original, el valor corregido, la fecha y el turno, permitiendo incluir el feedback del usuario en la prediccion.

Finalmente, la entidad Alerta gestiona las alertas de stock, asociando cada una a su correspondiente a usuarios e ingredientes, con indicadores de lectura y fechas de creación y actualización.
Todos los documentos incluyen timestamps (fecha\_creacion / fecha\_actualizacion) para auditoría.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/arquitectura-base-datos.png}
    \caption{Arquitectura de Base de Datos de SmartStocker.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:arquitectura-base-datos}
\end{figure}

\subsection{Pipeline ETL}\label{sec:pipeline-etl}

Con el objetivo de permitir la ingesta automática de las ventas, a fin de actualizar tanto los dashboards visualizados en la aplicación, activar las correspondientes alertas de stock si fuera necesario y disponibilizar la información para el entrenamiento del modelo predictivo, se implementó un pipeline de ETL mediante el cual se procesan las distintas ventas. La primera parte de este proceso es recibir y procesar las ventas que ocurren, para lo cual se diseñaron distintas Lambdas, ajustadas al distinto formato en el que las plataformas pueden enviar los datos de una venta realizada. En estas se analiza la información recibida y en base a ello se genera una nueva entrada en la entidad Ventas. Dado que estas instancias Lambda estarán atendiendo peticiones de sistemas externos, se decidió que el procesamiento que ocurre en ellas sea lo más rápido y sencillo posible, a fin de devolver una respuesta a la brevedad.

En base a esto, se implementó el uso de AWS SQS, permitiendo de esta forma que el resto de procesamiento requerido para transformar la venta en el dato requerido por el modelo ocurra en una Lambda distinta, que funciona como consumidor de la cola implementada en SQS, donde al finalizar la primer Lambda se encola un mensaje conteniendo el Id de la venta creada en DocumentDb, para que esta sea procesada por el consumidor. Esto nos brinda un procesamiento asincrónico y desacoplado de estas tareas que pueden ser más lentas, y permite que ocurran a un ritmo distinto de la Lambda inicial expuesta al resto de los sistemas de venta.

Esta segunda Lambda se encargará de procesar la venta, actualizando los niveles de stock y generando alertas de nivel del mismo si fuera necesario, para cada ingrediente utilizado en cada uno de los productos que integran cada venta.

Por último, al finalizar esta Lambda la información de cada una de las ventas es almacenada en S3 en formato CSV, generando una fila por cada producto involucrado en cada una de las ventas, disponible para ser usada al momento de entrenar el modelo, durante el paso de consolidación histórica, donde la información correspondiente a cada usuario se encontrará separada mediante el identificador único del usuario, a fin de garantizar la integridad de la información en los usos subsecuentes.

\subsection{Pipeline Machine Learning}\label{sec:pipeline-machine-learning}

El modelo predictivo de Machine Learning se encuentra diseñado de manera tal de poder considerar tres factores claves:

\begin{itemize}
    \item Factores cronológicos, siendo estos el día, semana y mes de la venta, como también el turno de trabajo en el cual fue realizada, y si la fecha corresponde a un feriado o no.
    \item Factores climáticos, específicamente temperatura promedio, la ocurrencia o no de lluvia, y la estación del año.
    \item La tendencia de cada producto, considerando como han sido las ventas de cada producto tanto de forma independiente, como también considerando la combinación producto y turno, siendo esto evaluado en el plazo de una semana y de un mes.
\end{itemize}

A fin de obtener la información relacionada a feriados y aspectos climáticos, se usan las APIs libres de ArgentinaDatos y Open-Meteo, respectivamente.

El algoritmo utilizado para el entrenamiento es CatBoost, perteneciente a la familia de algoritmos de regresión, seleccionado debido a su manejo nativo de variables categóricas.

Para la ejecución del entrenamiento en sí, se utilizan SageMaker Jobs, específicamente Processing Jobs para las tareas de Feature Engineering, y Training Jobs para el Entrenamiento propiamente del modelo.

Para ser capaces de realizar todo el proceso de entrenamiento de forma individual para cada usuario, se optó por implementar un pipeline, cuyo objetivo es entrenar de forma periódica un modelo actualizado para cada uno de ellos.

El mismo se encuentra implementado mediante el uso de AWS EventBridge, a fin de programar entrenamientos periódicos de forma semanal. Este disparará un evento que activará la primera Lambda, dedicada a consolidar los datos de la semana, y unificarlos con el dataset histórico ya existente. Como parte de esta, también se obtendrán los datos correspondientes a feriados y aspectos climáticos.

La segunda Lambda es la dedicada propiamente a coordinar las distintas fases del proceso de entrenamiento, Feature Engineering y Entrenamiento, cuya lógica se encuentra definida en sus respectivos scripts en Python.

Específicamente, sus funciones son las siguientes:

\begin{itemize}
    \item Feature engineering: Aquí se tomará el archivo histórico consolidado del usuario, y se obtendrán features adicionales para enriquecer el modelo, siendo estas las relacionadas a aspectos cronológicos y de tendencias de productos. También se realizan tratamiento de datos anómalos, y normalizaciones. La salida de este proceso son los dos datasets a utilizar para el entrenamiento del modelo, uno para el entrenamiento propiamente, y otro para su correspondiente validación, depositados dentro de S3.
    \item Entrenamiento: Encargado de utilizar los dos datasets creados previamente, e instanciar y ejecutar el entrenamiento en sí. Su salida es el archivo correspondiente al modelo ya entrenado.
\end{itemize}

La ventaja de que estas fases sean ejecutadas como SageMaker Jobs es que su performance aumenta notablemente en comparación de una ejecución en una Lambda estándar, puesto que este entorno cuenta con recursos ampliamente superiores en relación a ella.

Luego de estas etapas, se registra el modelo, asociando a él un tercer script de Python, que contiene la lógica a ejecutar al querer usarlo en una predicción, incluyendo el mínimo Feature Engineering requerido para que los datos a utilizar sean compatibles con el modelo. Y a su vez, este modelo queda asociado a un SageMaker Endpoint, que permite que la funcionalidad de predicción pueda ser realizada mediante peticiones HTTP a un endpoint dedicado.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/diagramaPipelineML.png}
    \caption{Diagrama del Pipeline de Machine Learning.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:diagrama-pipeline-ml}
\end{figure}

\subsection{Feature Engineering}\label{sec:feature-engineering}

Dentro del proceso de Feature Engineering, se generan una serie de features adicionales a partir de los datos históricos de ventas, con el objetivo de enriquecer el modelo y permitirle capturar patrones relevantes en la demanda, partiendo de los siguientes datos correspondientes al dataset generado en base a las ventas:

\begin{table}[H]
\centering
\caption{Datos base del dataset de ventas.}
\label{tab:dataset-base}

\renewcommand{\arraystretch}{1.25}
\begin{tabular}{|l|l|}
\hline
\textbf{Campo} & \textbf{Descripción} \\ \hline
cantidad & Cantidad vendida de un producto para una determinada fecha. \\
 & Variable objetivo a predecir por el modelo \\ \hline
fecha & Fecha de la venta en formato DD/MM/YYYY \\
 & (usado para agrupación y features temporales) \\ \hline
producto & Código del producto/ítem del menú \\ \hline
turno & Turno de venta \\ \hline
\end{tabular}

\vspace{0.3em}
\captionsetup{justification=centering}
{\small \textit{Fuente: Elaboración propia.}}
\end{table}

A partir de estos datos, se generan los siguientes tipos de features adicionales:

\textbf{Features Temporales:} Representan los aspectos cronológicos de una venta. A fin de capturar la naturaleza cíclica de estos datos, se optó por representar a las variables de día, semana y mes mediante el resultado de aplicar las funciones trigonométricas seno y coseno a sus correspondientes valores numéricos, de esta forma, se logra que el modelo pueda captar la continuidad entre el final y el comienzo de cada ciclo (por ejemplo, entre el día 31 y el día 1).

\textbf{Features Climáticas:} Representan los aspectos climáticos del momento donde se concretó una venta.

\textbf{Features de Lag:} Corresponden a variables que incorporan información de ventas pasadas en un intervalo temporal específico, permitiendo que el modelo aprenda patrones de comportamiento recurrentes en el tiempo. Por ejemplo, la variable \textit{lag\_1\_semana} representa el valor de ventas observado exactamente una semana antes del registro actual.

\textbf{Rolling Features:} Estas variables se obtienen a partir del cálculo de estadísticas móviles (como medias o desviaciones estándar) sobre ventanas temporales deslizantes. Su objetivo es reflejar la tendencia y la estabilidad reciente de las ventas, suavizando las fluctuaciones diarias. De esta forma, el modelo puede identificar cambios graduales en la demanda y diferenciar entre comportamientos estables y volátiles a corto o mediano plazo. En este caso, se calcularon medias(mean) y desviaciones estándar móviles(std) para ventanas de 1 semana(1w), 2 semanas(2w) y 4 semanas(4w), para cada producto(p), y las combinaciones producto-turno(pt) y producto-día(pdw).

Al finalizar el proceso de Feature Engineering, el dataset resultante contiene las siguientes variables:

\begin{table}[H]
\centering
\caption{Features Temporales.}
\label{tab:features-temporales}

\renewcommand{\arraystretch}{1.25}
\begin{tabular}{|l|l|}
\hline
\textbf{Feature} & \textbf{Descripción} \\ \hline
semana & Semana del mes \\ \hline
semana\_cos & Coseno del valor numérico de la semana \\ \hline
semana\_sin & Seno del valor numérico de la semana \\ \hline
mes & Número del mes (1-12) \\ \hline
mes\_cos & Coseno del valor numérico del mes \\ \hline
mes\_sin & Seno del valor numérico del mes \\ \hline
dia\_mes & Día del mes (1-31) \\ \hline
dia\_mes\_cos & Coseno del valor numérico del día del mes \\ \hline
dia\_mes\_sin & Seno del valor numérico del día del mes \\ \hline
es\_fin\_de\_semana & Indicador si es sábado o domingo \\ \hline
es\_feriado & Indicador si es feriado argentino \\ \hline
estacion & Estación del año en Hemisferio Sur (categórica) \\ \hline
\end{tabular}

\vspace{0.3em}
\captionsetup{justification=centering}
{\small \textit{Fuente: Elaboración propia.}}
\end{table}

\begin{table}[H]
\centering
\caption{Features Climáticas.}
\label{tab:features-climaticas}

\renewcommand{\arraystretch}{1.25}
\begin{tabular}{|l|l|}
\hline
\textbf{Feature} & \textbf{Descripción} \\ \hline
temperatura\_promedio & Categoría de temperatura \\ \hline
llovio & Indicador si llovió en el día \\ \hline
clima\_adverso & Indicador de condiciones climáticas adversas \\ \hline
descripcion\_clima & Descripción textual del clima \\ \hline
\end{tabular}

\vspace{0.3em}
\captionsetup{justification=centering}
{\small \textit{Fuente: Elaboración propia.}}
\end{table}

\begin{table}[H]
\centering
\caption{Features de Lag.}
\label{tab:features-lag}

\renewcommand{\arraystretch}{1.25}
\begin{tabular}{|l|l|}
\hline
\textbf{Feature} & \textbf{Descripción} \\ \hline
lag\_1\_semana & Total de ventas para la combinación de producto y turno \\ 
& exactamente una semana atrás \\ \hline
lag\_4\_semanas & Total de ventas para la combinación de producto y turno \\ 
& exactamente cuatro semanas atrás \\ \hline
\end{tabular}

\vspace{0.3em}
\captionsetup{justification=centering}
{\small \textit{Fuente: Elaboración propia.}}
\end{table}

\begin{table}[H]
\centering
\caption{Rolling Features.}
\label{tab:features-rolling}

\renewcommand{\arraystretch}{1.25}
\begin{tabular}{|l|l|}
\hline
\textbf{Feature} & \textbf{Descripción} \\ \hline
roll\_mean\_[ventana]\_[combinacion] & Promedio móvil de ventas \\ 
 & para ventanas de 1w, 2w y 4w \\ 
 & con combinaciones producto(p), producto-turno(pt) \\
 & y producto-día(pdw) \\ \hline
roll\_std\_[ventana]\_[combinacion] & Desviación estándar móvil de ventas \\ 
 & para ventanas de 1w, 2w y 4w \\
 & con combinaciones producto(p), producto-turno(pt) \\
 & y producto-día(pdw) \\ \hline
\end{tabular}

\vspace{0.3em}
\captionsetup{justification=centering}
{\small \textit{Fuente: Elaboración propia.}}
\end{table}

\subsection{Entrenamiento del modelo}\label{sec:entrenamiento-modelo}

Como parte del entrenamiento, se decidio usar la funcion de perdida Tweedie, debido a su capacidad para modelar variables continuas no negativas con distribución asimétrica y presencia de ceros, como ocurre en las ventas diarias de productos gastronómicos, donde es una ocurrencia normal que ciertos productos no sean vendidos en determinados días. Esto permite que el modelo se adapte mejor a estos patrones, mejorando la precisión de las predicciones.

A continuacion, se muestra un grafico donde se visualiza la importancia de las diez features mas relevantes, calculado usando la funcion PredictionValuesChange de CatBoost, la cual mide el impacto de cada feature en las predicciones del modelo al observar los cambios en los valores predichos cuando se modifica cada feature individualmente.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/importancia.png}
    \caption{Importancia de las features en el modelo.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:importancia-features}
\end{figure}

El modelo se entrenó con \textbf{2000 iteraciones} y una \textbf{tasa de aprendizaje de 0.0347}, lo que permite una convergencia progresiva sin overfitting. La \textbf{profundidad de los árboles (5 niveles)} limita la complejidad y mejora la estabilidad del modelo. Se utilizó una \textbf{regularización L2 de 44.95} y una \textbf{temperatura de muestreo de 1.79}, favoreciendo la diversidad de los árboles y reduciendo la varianza.  

El entrenamiento incorpora la técnica de \textit{early stopping} con \textbf{100 iteraciones}, de manera tal que el entrenamiento es finalizando cuando no se observan mejoras significativas entre iteraciones. Se empleó la política de crecimiento \textit{SymmetricTree}, propia de CatBoost, que genera árboles balanceados y eficientes.

Usando estos hiperparametros, logramos los siguientes resultados al evaluar el modelo:

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/resultados.png}
    \caption{Resultados del modelo.}
    {\textit{Fuente: Elaboración propia.}}
    \label{fig:resultados-modelo}
\end{figure}

Podemos ver que tanto el RMSE como el MAE presentan valores bajos, lo que indica que el modelo es apto para la tarea de predicción de ventas enfocada a la gestion de inventario.

\subsection{Inclusión del Feedback de usuario}\label{sec:inclusion-feedback-usuario}

A fin de incluir el feedback del usuario en las predicciones, se decidió implementar una lógica que ajuste la salida del modelo. Para ello, cada vez que el usuario informe que una predicción no es precisa en base a su experiencia, podrá informar el valor de ventas que él considera adecuado, ajustando esto el cálculo de stock requerido. Cuando esto ocurra de forma reiterada para una cierta combinación producto/turno dentro de un plazo de tiempo, se utilizaran los valores corregidos para calcular un valor de ajuste, teniendo más peso las correcciones recientes, y se aplicará a la predicción obtenida del modelo. 

Esto permite realizar ajustes sobre posibles tendencias que están ocurriendo de forma más rápida de la que el modelo es capaz de captarlas, sin modificar el proceso de entrenamiento del mismo, ya que eventualmente, si estos cambios en las tendencias pasarán a ser el comportamiento normal, el modelo lo aprenderá de forma natural conforme va accediendo a nueva información.

\section{Metodología de Desarrollo}\label{sec:metodologia-desarrollo}

El desarrollo de SmartStocker se realizó bajo el modelo de desarrollo en cascada, una metodología tradicional que organiza el trabajo en etapas secuenciales y claramente definidas. Cada fase depende del cumplimiento de la anterior, lo que permite mantener un flujo ordenado, documentado y con una trazabilidad precisa de los avances. Se consideró que este enfoque era el adecuado, dado que, luego del User Research, se cuenta con requerimientos bien definidos, lo que favoreció la planificación y la validación progresiva de resultados.

\subsection{Análisis y definición de requerimientos}\label{sec:analisis-definicion-requerimientos}

Tomando como base el User Research realizado, se comenzó con la identificación detallada de las necesidades del sistema, tanto funcionales como técnicas. Se establecieron los objetivos generales (optimización del stock y predicción de ventas en el sector gastronómico) junto con los requerimientos específicos de usabilidad, almacenamiento y procesamiento de datos. Esta etapa permitió definir con claridad el alcance del sistema y reducir incertidumbres en fases posteriores.

\subsection{Diseño conceptual y arquitectónico}\label{sec:diseño-conceptual-arquitectonico}

En esta instancia se elaboró la arquitectura general de SmartStocker, estructurada en tres capas: presentación, negocio y almacenamiento. Se seleccionaron tecnologías compatibles entre sí dentro del ecosistema AWS, priorizando la escalabilidad, la modularidad y la integración entre servicios. El diseño incluyó diagramas de componentes, flujos de datos y la definición de las interacciones entre los distintos módulos. Esto también incluyó las definiciones de qué aspectos serían considerados por el modelo de Machine Learning.

\subsection{Implementación y desarrollo}\label{sec:implementacion-desarrollo}

Durante esta fase se construyeron los distintos componentes del sistema siguiendo las especificaciones del diseño. El frontend fue desarrollado en Next.js y gestionado mediante AWS Amplify, mientras que la lógica de negocio se implementó en Node.js sobre funciones Lambda. Los modelos de machine learning se entrenaron y desplegaron utilizando Amazon SageMaker, integrando los flujos de datos procesados y almacenados en DocumentDB y S3.

\subsection{Validación e integración final}\label{sec:validacion-integracion-final}

Finalizada la implementación, se llevaron a cabo pruebas de validación funcional, de rendimiento y de integración entre servicios. Se verificó el correcto funcionamiento de las integraciones, la coherencia de las predicciones y la estabilidad del entorno de despliegue, junto con el cumplimiento de los requerimientos tanto funcionales como no funcionales.